[
  {
    "path": "posts/2021-01-14-enso-and-regression-to-the-mean/",
    "title": "ENSO and regression to the mean",
    "description": "How a recent paper published in Nature was pray to regression to the mean.",
    "author": [
      {
        "name": "Elio Campitelli",
        "url": "https://eliocamp.github.io/"
      }
    ],
    "date": "2020-01-15",
    "categories": [
      "ENSO",
      "statistics"
    ],
    "contents": "\nOn a recent article, Cai et al. (2020) used a perturbed ensemble of 40 members to show that members with relatively low El Niño Southern Oscillation (ENSO) variability at the beginning of the simulated period have a greater increase in ENSO variability towards the end of the simulated period than members with relatively high ENSO variability. They take this as evidence of ENSO self-regulation which would, if real, have important implications for future projections of ENSO variability under global warming. Here, I show that their results are not surprising, are likely product of simple regression to the mean and have no physical interpretation.\nIntroduction\nThe Community Earth System Model Large Ensemble model (Kay et al. 2015) consists of 40 climate simulations (members) that ran from 1920 to 2100 with identical external forcing and physics. Their only difference is a small, round-off error, perturbation in their atmospheric initial conditions. Cai et al. (2020) computed, for each member, the variability (standard deviation) of an index of Eastern-Pacific ENSO they call “E-index” for the first and last 50 years of the simulation. Owing to the effect of the various initial conditions, the variability in the E-index varied between members. I show their main result in Figure 1, which reproduces their Figure 1b. It shows a negative correlation between the initial E-index variability and its future change, defined as the difference between the final and the initial E-index variability.\n\nShow code\nlibrary(magrittr)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(patchwork)\ntheme_set(theme_minimal(base_size = 10) + theme(panel.grid = element_blank()))\n\n\n\n\nShow code\nobs_paper <- fread(here::here(\"public_data\", \"enso-data-fig1.csv\")) %>% \n  .[, final := initial + change]\nmoments <- obs_paper[, .(mean_initial = mean(initial), \n                         sd_initial = sd(initial),\n                         mean_final = mean(final),\n                         sd_final = sd(final))]\n\n\n\n\nShow code\nset.seed(42)\nmembers <- 40\nB <- 10000\nsims_normal <- CJ(sim = seq_len(B), member = seq_len(members)) %>% \n  .[, `:=`(initial = rnorm(.N, moments$mean_initial, moments$sd_initial),\n           final   = rnorm(.N, moments$mean_final, moments$sd_final))] %>% \n  .[, change := final - initial]\n\n\n\n\n\nShow code\ncor <- obs_paper[, cor.test(initial, change)]\n\ncor_text <- with(cor, paste0(\"R = \", signif(estimate, 2), \"\\nP ~ \", signif(p.value, 2)))\n\nobs_paper[, rank := cut_number(initial, 3)]\n\nobs_paper %>% \n  ggplot(aes(initial, change)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#0e9a83\") +\n  annotate(\"text\", label = cor_text, x = .51, y = 0, hjust = 0, size = 4) +\n  scale_x_continuous(\"Initial E-index variability (s.d.)\") +\n  scale_y_continuous(\"Change in E-index variability (s.d.)\") \n\n\n\n\nFigure 1: Reproduction of Figure 1b from Cai et al. (2020) based on digitised values. The horizontal axis shows the initial variability of their ENSO index for the first 50 years of simulation (1920 – 1969) and the vertical axis shows the difference between the variability of their ENSO index for the last 50 years of the simulation (2050 – 2099) and the first 50 years.\n\n\n\nFrom this negative correlation, Cai et al. (2020) conclude that “strikingly, in experiments with initially higher ENSO variability (…), [its] amplitude in the future a century later [is] systematically smaller, and vice versa”. They attribute this to a novel mechanism of self-regulation involving non-linear thermal damping through upper-ocean heat exchange and stratification.\nSimulations\nTo test how striking this result really is, I created \\(10^{4}\\) simulations of 40 pairs of random numbers representing the initial and final variability of the E-index for 40 hypothetical ensemble members. The random numbers were taken from independent normal distribution with \\(\\mu=0.8\\) and \\(\\sigma = 0.14\\) for the initial variability and \\(\\mu=0.93\\), \\(\\sigma = 0.072\\) for the final variability. These are the mean and standard deviation from the observed values derived from Figure 1.\nAs each simulated observation is independent from the rest, this simulations serve as a plausible model for the null hypothesis that the initial variability of ENSO does not influence it’s future change.\n\nShow code\ntwo_plots <- function(sim, obs, n = 1:10) {\n  fits <- sim[, metR::FitLm(change, initial, se = TRUE), by = sim] %>% \n    .[term != \"(Intercept)\"] %>% \n    .[, p_value := pt(abs(estimate)/std.error, df, lower.tail = FALSE), by = sim]\n  \n  obs_fits <- obs[, metR::FitLm(change, initial, se = TRUE)] %>% \n    .[term != \"(Intercept)\"] %>% \n    .[, p_value := pt(abs(estimate)/std.error, df, lower.tail = FALSE)]\n  \n  p_value <- fits[, mean(r.squared >= obs_fits$r.squared)]\n  \n  fit_density <- as.data.table(density(fits[term != \"(Intercept)\"]$r.squared)[c(\"x\", \"y\")])\n  \n  x_pval <- mean(fits[term != \"(Intercept)\"][r.squared >= obs_fits$r.squared]$r.squared)\n  y_pval <- mean(fit_density$y)\n  \n  sim[sim %in% 1:10] %>% \n    .[, change := change] %>% \n    ggplot(aes(initial, change)) +\n    geom_point(size = 0.4, alpha = 0.3) + \n    geom_point(data = obs, size = 0.7) +\n    geom_smooth(data = obs, method = \"lm\", se = FALSE, size = 1.4,\n                fullrange = TRUE, color = \"#0e9a83\") +\n    geom_smooth(method = \"lm\", aes(group = sim), se = FALSE, fullrange = TRUE, \n                color = \"black\", size = 0.1, alpha = 0.5) +\n    scale_x_continuous(\"Initial E-index variability (s.d.)\") +\n    scale_y_continuous(\"Change in E-index variability (s.d.)\") +\n  # coord_equal()  +\n  \n  fit_density %>% \n    ggplot(aes(x, y)) +\n    geom_area(data = ~.x[x >= obs_fits$r.squared], fill = \"#4d4d4d\") +\n    annotate(\"text\", size = 6, color = \"white\",\n             label = scales::percent(p_value), x = x_pval, y = y_pval) +\n    geom_line() +\n    geom_vline(xintercept = obs_fits$r.squared, color = \"#0e9a83\", size = 1.4) +\n    scale_x_continuous(\"r²\") +\n    scale_y_continuous(NULL) +\n    \n    \n    plot_annotation(tag_levels = \"a\")\n}\n\ncompute_pvalue <- function(sim, obs) {\n  fits <- sim[, metR::FitLm(change, initial, se = TRUE), by = sim] %>% \n    .[term != \"(Intercept)\"] %>% \n    .[, p_value := pt(abs(estimate)/std.error, df, lower.tail = FALSE), by = sim]\n  \n  obs_fits <- obs[, metR::FitLm(change, initial, se = TRUE)] %>% \n    .[term != \"(Intercept)\"] %>% \n    .[, p_value := pt(abs(estimate)/std.error, df, lower.tail = FALSE)]\n  \n  fits[, mean(r.squared >= obs_fits$r.squared)]\n}\n\n\n\n\n\nShow code\ntwo_plots(sims_normal, obs_paper)\n\n\n\n\nFigure 2: a. Ten simulated ensembles of 40 members drawn from random numbers (see description in text) in small dot and their linear regression in fine lines. The observed values from Cai et al. (2020) in big dots and the linear regression in think, green. b. Estimated probability density of the coefficient of determination (\\(r^2\\)) under the null hypothesis model. The vertical bar shows the observed \\(r^2\\) and the shaded area is the proportion of simulated samples from the null hypothesis model with a \\(r^2\\) equal or greater than the observed one.\n\n\n\nFigure 2.a shows a random sample of 10 of these simulations in small dots and their respective linear fit in fine lines. Comparing these random simulations with the observed values taken from Cai et al. (2020) – shown in big dots and thick, green line – puts into perspective the strength of their evidence. The spread of the simulated data is very similar to the real data and all 10 simulation have a steeper regression slope. Both sets are so similar that it would be virtually impossible to distinguish between the simulated and real data if not for the different size of the points.\n\nShow code\np_value <- compute_pvalue(sims_normal, obs_paper)\n\n\n\nTo quantify how surprising the observed effect actually is, Figure 2.b shows the estimated probability density of the coefficient of determination (\\(r^2\\)) from the linear fit of the 10^{4} simulations and the observed value as a vertical line. 74% of simulations show an \\(r^2\\) equal or greater than the observed one. This translates to a p-value of 0.74; significantly higher than \\(1.4\\times 10^{-12}\\), naively computed from the linear regression.\nThen, it’s evidently clear that under this model of the null hypothesis the observed negative correlation is not only unsurprising, but completely expected.\nThe fact that the initial value of a variable is negatively correlated with its “future change” is one of the manifestation of the general principle of regression to the mean first observed by Galton in 1889 (Francis Galton 1889). He noted that very tall parents tended to have relatively shorter children while tall children tended to have relatively shorter parents.\nIn a perturbed ensemble experiment some ensemble members will have higher initial ENSO variability than average, while other will have lower ENSO variability than average. If this initial ENSO variability is completely independent of further ENSO variability (e.g. the null hypothesis is true), then both groups are equally likely to have average variability further down the simulation. Thus, members which a high initial ENSO variability will tend to show – on average – a negative change in variability, an vice versa.\nFormal formula\nIt’s straightforward to show this effect mathematically. The correlation between two variables \\(x\\) and \\(z = y - x\\) can be written as:\n\\[\\begin{equation}\n\\tag{1}\n\\mathrm{cor}(x, y - x) = \\frac{\\mathrm{cov(x, y) - \\mathrm{var}(x)}}{\\sqrt{\\mathrm{var}(x)\\mathrm{var}(y) + \\mathrm{var}(x)^2 - 2\\mathrm{var}(x)\\mathrm{cov}(x, y)}}\n\\end{equation}\\]\nIf \\(x\\) and \\(y\\) are independent random variables, \\(\\mathrm{cov}(x, y) = 0\\) vanish and Equation (1) simplifies to\n\\[\\begin{equation}\n\\tag{2}\n\\mathrm{cor}(x, y - x)= \\frac{-1}{\\sqrt{\\mathrm{var}(y)/\\mathrm{var}(x) +1}}\n\\end{equation}\\]\nThis final formula shows that the correlation between \\(x\\) and \\(y - x\\) is bound to be negative and its magnitude depends only on the relationship between their variances. That is, if the variance of \\(y\\) is greater than the variance of \\(x\\), then the correlation will be small, and vice versa.\nApplying Equation (2) to the issue at hand, \\(x\\) becomes the initial ENSO variability and \\(y\\), the final ENSO variability and \\(\\mathrm{var}(x)\\), \\(\\mathrm{var}(y)\\) are the ensemble spread in initial and final ENSO variability, respectively. This means that, even in the case of no linear relation between initial and final variability, any process – either driven by physics or models – which reduces ensemble spread will lead to an even stronger negative linear relationship between the variables.\n\nShow code\nalpha_obs <- moments[, sd_final/sd_initial]^2\npred <- -1/sqrt(alpha_obs + 1)\n\n\n\nIn the case of equal variances, Equation (2) predicts a correlation of \\(-1/\\sqrt{2} \\sim -0.71\\). The observed correlation of -0.86 (Figure 1) is stronger This is explained by the reduced ensemble spread in ENSO variability between the initial and final periods, as the final spread is around 29% of the initial spread. For this value, Equation (2) predicts a correlation of -0.88, which is very close (if a bit stronger) to the observed value.\n\nConclusion\nThe previous analysis puts the strength of Cai et al. (2020) evidence into perspective. That the change in ENSO variability is greater in ensemble members with initially low ENSO variability is not at all surprising. By simulating the null hypothesis, I show that a negative correlations as strong or stronger than the one observed by Cai et al. (2020) can be expected 74% of the time.\nThese strong negative correlation can be explained by regression towards the mean and reduced ensemble spread in the final period compared to the initial period. I don’t think it is possible to identify the source of the spread reduction. It might be a real response to the forcing scenario or inability of the ensemble to capture all the sources of variability. In particular, all members share the same physics and boundary conditions, therefore I believe it would not be unexpected if all members slowly converged to a similar state. Kay et al. (2015)’s Figure 2 does appear to show that the ensemble spread is slightly higher before 1970. Of note, recently Bengtsson and Hodges (2019) observed secular reductions of ensemble spread in mean surface temperature in an ensemble whose members where also all forced with the same radiative conditions.\nFailing to account for regression to the mean is a fallacy that affects many fields of science – including behavioural science (Kelly and Price 2005) and medicine (Chuang-Stein and Tong 1997) – and features prominently in popular culture, such as the “Sports Illustrated cover jinx” – the perception that an athlete’s performance will be “cursed” after appearing in the cover of Sports Illustrated (Goldacre 2008). Cai et al. (2020) is not the first paper nor will be the last to fall for it.\n\n\n\nBengtsson, L., and K. I. Hodges. 2019. “Can an Ensemble Climate Simulation Be Used to Separate Climate Change Signals from Internal Unforced Variability?” Clim Dyn 52 (5): 3553–73. https://doi.org/10.1007/s00382-018-4343-8.\n\n\nCai, Wenju, Benjamin Ng, Tao Geng, Lixin Wu, Agus Santoso, and Michael J. McPhaden. 2020. “Butterfly Effect and a Self-Modulating El Niño Response to Global Warming.” Nature 585 (7823): 68–73. https://doi.org/10.1038/s41586-020-2641-x.\n\n\nChuang-Stein, Christy, and Donald M Tong. 1997. “The Impact and Implication of Regression to the Mean on the Design and Analysis of Medical Investigations.” Statistical Methods in Medical Research 6 (2): 115–28. https://doi.org/10.1177/096228029700600203.\n\n\nFrancis Galton. 1889. Natural Inheritance.\n\n\nGoldacre, Ben. 2008. Bad Science. HarperCollins UK.\n\n\nKay, J. E., C. Deser, A. Phillips, A. Mai, C. Hannay, G. Strand, J. M. Arblaster, et al. 2015. “The Community Earth System Model (CESM) Large Ensemble Project: A Community Resource for Studying Climate Change in the Presence of Internal Climate Variability.” Bull. Amer. Meteor. Soc. 96 (8): 1333–49. https://doi.org/10.1175/BAMS-D-13-00255.1.\n\n\nKelly, Colleen, and Trevor D. Price. 2005. “Correcting for Regression to the Mean in Behavior and Ecology.” Am Nat 166 (6): 700–707. https://doi.org/10.1086/497402.\n\n\n\n\n",
    "preview": "posts/2021-01-14-enso-and-regression-to-the-mean/distill-preview.png",
    "last_modified": "2021-01-15T13:46:37-03:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-01-15-sao-and-jet/",
    "title": "The meridional structure of the Semiannual Oscillation",
    "description": "How to filter out extra-tropical variabilty to highlight the structure of the Semiannual Oscillation using just multiple linear regression.",
    "author": [
      {
        "name": "Elio Campitelli",
        "url": "https://eliocamp.github.io/"
      }
    ],
    "date": "2020-01-15",
    "categories": [
      "Semiannual Oscillation",
      "general circulation",
      "tropics",
      "stratosphere"
    ],
    "contents": "\nSome time ago, with a Journal Club I’m part of (shout-out to Go stratospheric!), we read “Representation of the equatorial stratopause semiannual oscillation in global atmospheric reanalyses” (Kawatani et al. 2020), a paper about the Semiannual Oscillation (SAO). One figure (Figure 1) piqued our interest. The SAO is supposed to be a characteristic of the tropical stratosphere and be… you know… semiannual. But in Figure 1, the more sticking feature is extra-tropical and with an annual cycle.\n\n\nShow code\nknitr::include_graphics(here::here(\"img\", \"sao-jet-fig8.png\"))\n\n\n\n\nFigure 1: Figure 8 from Kawatani et al. (2020): “Time–latitude sections of climatological mean annual cycle of the zonal mean zonal wind for (a) SABER, (b) MLS, and (c–i) each reanalysis at 1 hPa. The contour intervals are 10 m s−1. Climatology is calculated from 1980 to 2010 in the reanalyses, from 2002 to 2016 in SABER, and from 2005 to 2016 in MLS.”\n\n\n\nWe quickly realised that there’s more going on there than the SAO. Is there a way to filter out the rest of the variability and only look at the SAO-related variabiltiy?\nAs always, first thing first. Download the data and replicate the figure. Kawatani et al. (2020) use data from many many reanalyses, but I’m only going to use data from ERA5.\n\nShow code\nlibrary(magrittr)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(metR)\ntheme_set(theme_minimal(base_size = 10) + theme(panel.grid = element_blank()))\n\n\n\n\nShow code\n# This WILL take long. Go make yourself a cut of tea or brew some mate.\nera5_file <- here::here(\"_data\", \"era5-u.nc\")\n\nif (!file.exists(era5_file)) {\n  request <- list(\n    format = \"netcdf\",\n    product_type = \"monthly_averaged_reanalysis\",\n    variable = \"u_component_of_wind\",\n    pressure_level = c(\"1\", \"2\", \"3\", \"5\", \"7\", \"10\", \"20\", \"30\"),\n    year = c(\"1979\", \"1980\", \"1981\", \"1982\", \"1983\", \"1984\", \"1985\", \"1986\", \"1987\", \"1988\", \"1989\", \"1990\", \"1991\", \"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\", \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\"),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    time = \"00:00\",\n    grid = c(\"2.5\", \"2.5\"),   # we don't need high resolution\n    dataset_short_name = \"reanalysis-era5-pressure-levels-monthly-means\",\n    target = basename(era5_file)\n  )\n  \n  # Need to set up user with\n  # ecmwfr::wf_set_key() \n  ecmwfr::wf_request(request, path = dirname(era5_file))\n}\n\n\n\n\nShow code\nera5 <- ReadNetCDF(era5_file)\n\n\n\n\nShow code\nera5 %>% \n  .[level == 1] %>% \n  .[, .(u = mean(u)), by = .(latitude, month(time), level)] %>% \n  ggplot(aes(month, latitude)) +\n  geom_contour_fill(aes(z = u, fill = ..level..), \n                    breaks = AnchorBreaks(0, binwidth = 15, exclude =  0)) +\n  geom_contour_tanaka(aes(z = u), \n                      breaks =  AnchorBreaks(0, binwidth = 15, exclude =  0)) +\n  scale_y_latitude() +\n  scale_x_continuous(breaks = 1:12, labels = month.abb, expand = c(0, 0)) +\n  scale_fill_divergent_discretised(\"U\") +\n  facet_wrap(~level, labeller = labeller(level = function(x) paste0(x, \" hPa\")))\n\n\n\n\nFigure 2: Seasonal cycle of zonal mean zonal wind at 1 hPa\n\n\n\nFigure 2 replicated Figure 1 extending the latitude range to the rest of the globe. It becomes even clearer that the main variability is in the extratropics.\nNow, the SAO not only is supposed to be in the tropics, but it’s also restricted to levels higher than ~3 hPa. Figure 3 shows what’s going on at levels bewteen 1 hPa and 30 hPa.\n\n\nShow code\nlast_plot() %+%\n  era5[, .(u = mean(u)), by = .(latitude, month(time), level)]\n\n\n\n\nFigure 3: Same as Figure 2 but for multiple levels.\n\n\n\nThe variability in the extratopics is there in the lower levels. So I though, why don’t try to remove that lower-level signal? After looking at Figure 3 and trying around, I settled into representing the lower levels with 5 hPa and 20 hPa.\nSo, at each gridpoint I fit the model\n\\[\nU_{1hPa} = \\alpha U_{5hPa} + \\beta U_{20hPa} + \\epsilon_{1hPa}\n\\]\nWhere \\(U\\) is the zonal mean zonal wind at each level and \\(\\epsilon_{1hPa}\\) is the residual wind that I’m interested in. That is, the variability of zonal mean zonal wind at 1 hPa that is not (linearly) explained by the variability of the zonal mean zonal wind at the lower levels. For those paying attention, this is (I think) essentially removing the equivalent barotropic component in the wind.\n\nShow code\nfiltered  <- era5 %>% \n  .[level %in% c(1, 5, 20)] %>% \n  # .[, .(u = mean(u)), by = .(time, level, latitude)] %>%\n  dcast(time + latitude + longitude ~ level, value.var = \"u\") %>% \n  .[, u_resid := resid(lm(`1` ~ `5` + `20`)), by = .(latitude, longitude)] \n\n\n\nThe seasonal cycle of the residual zonal mean zonal wind in Figure 4 shows that the filtering really works! Now it really looks like the equatorial phenomenon that it’s supposed to be, and the semiannual cycle is plainly for all to see. 🎈.\n\nShow code\nfiltered %>% \n  .[, .(u = mean(u_resid)), by = .(month(time), latitude)] %>% \n  ggplot(aes(month, latitude)) +\n  geom_contour_fill(aes(z = u, fill = ..level..), \n                    breaks = AnchorBreaks(0, binwidth = 10, exclude =  0)) +\n  geom_contour_tanaka(aes(z = u), \n                      breaks =  AnchorBreaks(0, binwidth = 10, exclude =  0)) +\n  scale_y_latitude() +\n  scale_x_continuous(breaks = 1:12, labels = month.abb, expand = c(0, 0)) +\n  scale_fill_divergent_discretised(\"U\")\n\n\n\n\nFigure 4: Seasonal cycle of the residual zonal mean zonal wind.\n\n\n\nAnd for completitude, Figure 5 shows timeseries of zonal mean zonal wind at the equator, and averaged polarward of 30°. In the equator, the residual zonal wind is virtually identical to the unfiltered zonal wind.\n\nShow code\nfiltered %>% \n  .[, zone := fcase(latitude > 30, \"north of 30°N\",\n                    latitude < -30, \"south of 30°S\",\n                    latitude == 0, \"equator\",\n                    default = NA)] %>% \n  na.omit() %>% \n  .[, .(u = mean(`1`),\n        u_resid = mean(u_resid)), by = .(time, zone)] %>% \n  melt(id.vars = c(\"time\", \"zone\")) %>% \n  ggplot(aes(time, value)) +\n  geom_line(aes(color = variable)) +\n  scale_color_brewer(NULL, palette = \"Dark2\", labels = c(u = \"U\", \n                                                         u_resid = \"Residual U\")) +\n  scale_y_continuous(NULL) +\n  facet_wrap(zone~., ncol = 1) \n\n\n\n\nFigure 5: Timeseries of zonal mean zonal wind and residual zonal wind in the equator, averaged north of 30°N and south of 30°S\n\n\n\nSo the conclusion, I think, is that the meridional structure was a function of the polar jets, and that looking at the SAO by looking at zonal mean zonal wind in the equator is fine.\n\n\n\nKawatani, Yoshio, Toshihiko Hirooka, Kevin Hamilton, Anne K. Smith, and Masatomo Fujiwara. 2020. “Representation of the Equatorial Stratopause Semiannual Oscillation in Global Atmospheric Reanalyses.” Atmospheric Chemistry and Physics 20 (14): 9115–33. https://doi.org/10.5194/acp-20-9115-2020.\n\n\n\n\n",
    "preview": "posts/2021-01-15-sao-and-jet/distill-preview.png",
    "last_modified": "2021-01-15T13:27:38-03:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-01-14-wave4/",
    "title": "Analysis of \"Global wave number-4 pattern in the southern subtropical sea surface temperature.\"",
    "description": "A recent paper claims to have detected a global wave-4 pattern in subtropical SSTs. But have they really?",
    "author": [
      {
        "name": "Elio Campitelli",
        "url": "https://eliocamp.github.io/"
      }
    ],
    "date": "2020-01-14",
    "categories": [
      "zonal waves",
      "general circulation"
    ],
    "contents": "\nThis are some quick notes on Global wave number-4 pattern in the southern subtropical sea surface temperature (Senapati, Dash, and Behera 2021). The article claims to discover a wave-4 pattern in the southern Sea Surface Temperature (SST). Their basic method is to perform Empirical Orthogonal Function (EOF) to SST between 55°S and 20°S. They discard the first EOF as uninteresting because it’s “ENSO-like” (unsurprising) and focus on the second EOF, whose spatial pattern is in Figure 1.\n\n\n\n\nFigure 1: Panel a from Senapati, Dash, and Behera (2021)’s Figure 1: Spatial pattern of second leading EOF mode of SST anomaly over the region (20°S-55°S) from HadISST.\n\n\n\nFirst things first. Download the data and try to reproduce their figure.\n\nShow code\n# packages\nlibrary(magrittr)\nlibrary(data.table)\nlibrary(metR)\nlibrary(ggplot2)\n\n\n# fast detrend.\nDetrend <- function(y, x) {\n  nas <- is.na(y)\n  m <- mean(y, na.rm = TRUE)\n  if (!hasArg(x)) x <- seq_along(y)\n  y[!nas] <- .lm.fit(cbind(1, x[!nas]), y[!nas])$residuals\n  return(y + m)\n}\n\ntheme_set(theme_minimal() + \n            theme(panel.grid = element_blank()))\n# simple and dirty map\nmap <- ggplot2::map_data(\"world2\") %>%\n  subset(lat %between% c(-90, -0))\n\nquick_map <- list(geom_polygon(data = map,\n                               aes(long, lat, group = group), fill = \"white\", color = \"black\",\n                               size =0.2),\n                  scale_x_longitude(),\n                  scale_y_latitude(ticks = 10),\n                  coord_quickmap(ylim = c(-55, -20)))\n\n\n\n\nShow code\n# Download and decompress HadSST data\nhad_file <- here::here(\"_data\", \"hadsst.nc\")\nif (!file.exists(had_file)) {\n  hadsst <- \"https://www.metoffice.gov.uk/hadobs/hadisst/data/HadISST_sst.nc.gz\"\n  had_zip <- tempfile()\n  \n  download.file(hadsst, had_zip, mode = \"wb\")  \n  R.utils::gunzip(had_zip, had_file, remove = FALSE)\n}\n\n\n\n\nShow code\n# Read data and detrend\nsst <- ReadNetCDF(had_file, \n                   vars = c(\"sst\"),\n                   subset = list(latitude = c(-90, -0),\n                                 time = c(\"1979-01-01\", \"2018-12-31\"))) %>% \n  setnames(c(\"longitude\", \"latitude\"), c(\"lon\", \"lat\")) %>% \n  na.omit() %>% \n  .[, lon := ConvertLongitude(lon)] %>% \n  .[, sst := Detrend(Anomaly(sst)), by = .(lon, lat, month(time))]\n\n\n\n\nShow code\neofs <- sst[lat %between% c(-55, -20)] %>%\n  copy() %>% \n  .[, sst := sst*sqrt(cos(lat*pi/180))] %>% \n  EOF(sst ~ time | lat + lon, n = 1:2, data = .)\n\n\n\n\n\nShow code\nggplot(eofs$right, aes(lon, lat)) +\n  geom_contour_fill(aes(z = -sst)) +\n  scale_fill_divergent(guide = \"none\") +\n  quick_map + \n  facet_wrap(PC~., ncol = 1)\n\n\n\n\nFigure 2: Spatial patterns of the frist and second leading EOFs of detrended monthly anomalies of SST between 55°S and 20°S weighted by the square root of the cosine of latitude.\n\n\n\nAnd indeed. The first EOF is kind of ENSO-like (not really full ENSO, because I’m missing the equatorial SSTs, which is where ENSO really shines) and the second EOF looks pretty much identical to the their Figure 1.a save the different prime meridian. The time series associated with the second EOF is also almost exactly the same.\n\n\nShow code\ncut(eofs, 2) %>% \n  .$left %>%\n  copy() %>% \n  .[, sst5 := frollmean(sst, 5, align = \"center\")] %>% \n  ggplot(aes(time, -sst)) +\n  geom_hline(yintercept = 0, size = 0.2, color = \"gray50\")  +\n  geom_line(aes(y = -sst5))  +\n  geom_line(color = \"gray\") +\n  \n  scale_y_continuous(NULL) +\n  scale_x_datetime(date_breaks = \"5 years\", date_labels = \"%Y\")\n\n\n\n\nFigure 3: Temporal pattern of the second EOF in gray with a 5-month running mean in black.\n\n\n\nOK, I’m on the right track.\nNow, my main concern with this paper is whether this pattern is actually, as the title of the paper says, a global pattern. EOF is a great technique for dimensionality reduction, but it’s too easy to end up with statistical patterns that are a mix of actual physical patterns or even just noise.\nThe authors agree, and they say that..\n\nIn order to examine the synchronization of the W4 pattern among all the basins, point correlation analysis has been performed. For this purpose, eight points [i(37.5°S, 173.5°W), ii(37.5°S, 133.5°W), iii(44.5°S, 90.5°W), iv(39.5°S, 40.5°W), v(29.5°S, 2.5°W), vi(41.5°S, 41.5°E), vii(30.5°S, 86.5°E), viii(35.5°S, 130.5°E)] corresponding to the loading centres are selected (marked by green dots, i-viii, in Fig. 1a). The time series of SST anomaly is computed at each grid point after removing the contributions of the first EOF mode (henceforth, reconstructed SST anomaly). Further, point correlation is performed for the time series at the loading centers (Fig. 1a) with the reconstructed SST anomaly (Fig. 2a–h corresponding respectively to points (i) to (viii) of Fig. 1a).\n\nThe problem, IMHO, is that their Figure 2 doesn’t really show as much synchronisation as they claim. First, let’s reproduce it here.\n\nShow code\n# Define points of interest\npoints <- tibble::tribble(~lat, ~lon,\n                          -37.5, -173.5,\n                          -37.5, -133.5,\n                          -44.5, -90.5,\n                          -39.5, -40.5, \n                          -29.5, -2.5, \n                          -41.5, 41.5,\n                          -30.5, 86.5,\n                          -35.5, 130.5) %>% \n  as.data.table() %>% \n  .[, lon := ConvertLongitude(lon)] %>% \n  .[, id := tolower(as.roman(seq_len(.N)))] %>% \n  .[, sign := rep(c(-1, 1), 4)]   # sign of original correlation\n\n\n\n\nShow code\n# Reconstruct SST from leading EOF  and add it to \n# original data                     \nsst_reconstruct <- predict(eofs, n = 1) %>% \n  setnames(\"sst\", \"sst_reconstructed\")\n\nsst <- sst[sst_reconstruct, on = .NATURAL]\nrm(sst_reconstruct)\n\n\n\n\nShow code\n# Compute correlation maps of  points of interest,\n# both with the orignial sst and sst with filtered EOF1\n# (for compatison)\ncorrs <- sst[points, on = .NATURAL] %>% \n  .[, \":=\"(lon = NULL, lat = NULL)] %>% \n  setnames(c(\"sst\", \"sst_reconstructed\"), c(\"ref\", \"ref_reconstructed\")) %>% \n  .[sst, on = \"time\", allow.cartesian = TRUE] %>% \n  .[, .(correlation = cor(sst, ref),\n        correlation_reconstructed = cor(sst - sst_reconstructed, ref - ref_reconstructed)),\n    by = .(lon, lat, id, sign)]\n\n\n\n\n\nShow code\ncorrs %>% \n  melt(measure.vars = c(\"correlation\", \"correlation_reconstructed\")) %>% \n  ggplot(aes(lon, lat)) +\n  geom_contour_fill(aes(z = -value*sign), \n                    breaks = AnchorBreaks(anchor = 0, binwidth = 0.1)) +\n  quick_map +\n  geom_point(data = copy(points)[, id := NULL], shape = 21, fill = NA) +\n  geom_point(data = copy(points), shape = 21, color = \"black\", fill =  \"#0e9a83\") +\n  scale_fill_divergent() +\n  facet_grid(id~variable, labeller = labeller(variable = c(correlation = \"SST\", \n                                                           correlation_reconstructed = \"SST - EOF1\")))\n\n\n\n\nFigure 4: Correlation maps of SST and SST with the first EOF filterred out with the corresponding SST at each one of the points of interest. Compare withFigure 2 of Senapati, Dash, and Behera (2021).\n\n\n\nI purposedly computed the two versions. The panels on the right should be a reproduction of Senapati, Dash, and Behera (2021)’s Figure 2. It’s hard to compare them because of the different colour palettes and scale limits (the authors really chose the parameters that enhanced small correlations), but I personally don’t see much coherency. The first three rows do show high correlations between the three points in the Pacific, which in the unfiltered data looks very much like the well-known PSA pattern that appears as a response to El Niño Southern Oscillation.\nAnother way to look at it is with by plotting \\(r^2\\) which directly quantifies the degree of (linear) dependence between points.\n\n\nShow code\ncorrs %>% \n  ggplot(aes(lon, lat)) +\n  geom_contour_fill(aes(z = correlation_reconstructed^2, \n                        fill = ..level..), breaks = seq(.1, 1, by = 0.1)) +\n  quick_map +\n  geom_point(data = copy(points)[, id := NULL], shape = 21, fill = NA) +\n  geom_point(data = copy(points), shape = 21, color = \"black\", fill =  \"#de3e80\") +\n  scale_fill_viridis_c(oob = scales::squish,\n                       super = ScaleDiscretised) +\n  facet_grid(id~.)\n\n\n\n\nFigure 5: Coefficient of determination (\\(r^2\\)) computed from the correlations with the filtered SST in Figure 4. Contours only show areas with \\(r^2 > 0.1\\).\n\n\n\nAgain, aside from the points in the Pacific, there is not a lot of long-range relationships between points. As I see it, I strongly suspect that this PC2 pattern is not really robustly global.\nLet’s try something else. From the correlation maps above (and previous knowledge), it’s pretty obvious that the Pacific sector does behave somewhat coherently. So what I’m going to do is to split the spatial pattern into the Pacific basin (between 150°E and 290°E) and the Atlantic-Indian basins (the rest of the hemisphere). Then, I’m going to project each pattern onto the corresponding SST fields to get two indices. If the patterns is really coherent in time, then both indices must be strongly correlated.\n\nShow code\nseries <- eofs$right %>% copy() %>% \n  .[PC == \"PC2\"] %>% \n  .[, basin := ifelse(lon %between% c(150, 290), \"pacific\", \"atlantic\")] %>% \n  setnames(\"sst\", \"EOF\") %>% \n  .[sst, on = c(\"lon\", \"lat\")] %>% \n  .[, cor(sst, EOF), by = .(time, basin)]\n\n\n\n\nShow code\n# Relationship between the two indices. \nseries %>% \n  dcast(time ~ basin) %>% \n  ggplot(aes(pacific, atlantic)) +\n  geom_point() +\n  geom_label(data = ~.x[, .(cor(pacific, atlantic))], \n            aes(label = paste0(\"cor= \", signif(V1, 2))), \n            x = -0.6, y = .5, size = 7) +\n  geom_smooth(method = \"lm\") +\n  scale_x_continuous(\"Pacific index\") +\n  scale_y_continuous(\"Atlantic-Indian index\")\n\n\n\n\nFigure 6: Relationship between the Pacific index and Atlantic-Indian index.\n\n\n\nI mean… A correlation of 0.37 is not nothing, but it’s also not a lot.\nNow one last test. Let’s do the correlation map of each index. Again, if the pattern is really global, then the correlation map of the Pacific Index should also show the Atlantic-Indian pattern and vice versa.\n\nShow code\npatterns <- eofs$left[PC == \"PC2\"] %>% \n  setnames(c(\"sst\", \"PC\"), c(\"V1\", \"basin\")) %>% \n  rbind(., series, use.names = TRUE) %>% \n  .[sst, on = \"time\", allow.cartesian = TRUE] %>% \n  .[, .(correlation = cor(V1, sst)), by = .(lon, lat, basin)] \n\nlines <- CJ(lon = c(150, 290),\n            basin = c(\"pacific\", \"atlantic\"))\n\n\n\n\nShow code\npatterns %>% \n  ggplot(aes(lon, lat)) +\n  geom_contour_fill(aes(z = -correlation, fill = ..level..), \n                    breaks = AnchorBreaks()) +\n  quick_map + \n  geom_vline(data = lines, aes(xintercept = lon)) +\n  scale_fill_divergent_discretised(limits = c(-1, 1)) +\n  facet_wrap(basin~., ncol = 1, labeller = labeller(basi = c(pacific = \"Pacific\", \n                                                             atlantic = \"Atlantic-Indian\")))\n\n\n\n\nFigure 7: Correlation patterns with the Pacific index, the Atlantic-Indian index and the PC2.\n\n\n\nAgain… kinda? For the Atlantic-Indian index, the Pacific signal is barely there and it’s actually completely missing in the Western Pacific. And for the Pacific index, the there is some signal in the Indian ocean, but barely any signal in the Atlantic.\n🤷. Take it as you will. From what I’ve seen here, I remain unconvinced that this is a global pattern of SST.\n\n\n\nSenapati, Balaji, Mihir K. Dash, and Swadhin K. Behera. 2021. “Global Wave Number-4 Pattern in the Southern Subtropical Sea Surface Temperature.” Scientific Reports 11 (1): 142. https://doi.org/10.1038/s41598-020-80492-x.\n\n\n\n\n",
    "preview": "posts/2021-01-14-wave4/distill-preview.png",
    "last_modified": "2021-01-15T13:05:04-03:00",
    "input_file": {},
    "preview_width": 960,
    "preview_height": 403
  }
]
